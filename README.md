<h1 align="center">ğŸ§  MEDA</h1>

<p align="center">
  <img src="/frontend/public/logo.png" alt="Meda Logo" width="150">
</p>

<p align="center"><b>Medical Evidence Driven Assistant</b></p>
<p align="center">
  <em>A research-focused RAG system built as part of an NLP course project</em>
</p>

---

## ğŸ“ Context

This project was developed as part of the **Natural Language Processing (NLP) course final project**, with the goal of exploring real-world applications of LLMs and retrieval-augmented generation (RAG) pipelines in the **medical domain**.

---

## ğŸ”¬ Motivation

Medical questions require **reliable**, **evidence-based**, and **interpretable** answers. Large Language Models (LLMs) are powerful, but they often hallucinate. MEDA solves this by:

- Retrieving relevant content from trusted sources (PubMed, clinical guidelines)
- Generating answers grounded in real documents
- Showing source context for transparency

---

## ğŸ§ª Project Goals

- ğŸ§  Apply NLP techniques to build a domain-specific Q&A system  
- ğŸ” Integrate vector search (retrieval) with generation (RAG)  
- ğŸ“š Work with real medical data: abstracts, notes, recommendations  
- ğŸ¤– Use modern frameworks like LangChain, and Mistral  

---

## ğŸ§  System Overview

**MEDA** is a Retrieval-Augmented Generation (RAG) system for answering medical queries. It uses a combination of document search, LLM generation, and interface design to create a helpful medical assistant.

---

## ğŸ“ Architecture

Below is the architecture diagram of MEDA, showing how user queries flow through the system:

<p align="center">
  <img src="docs/architecture.png" alt="MEDA Architecture Diagram" width="600"/>
</p>

Main flow:
1. User submits a medical question via the Web UI.
2. Backend calls Retriever (Chroma) to find relevant document chunks.
3. The query and context are used to construct a prompt.
4. LLM (Mistral or Hugging Face) generates a grounded answer.
5. Answer and source snippets are returned to the UI.

---

## âš™ï¸ Tech Stack

| Layer        | Tools & Libraries                                |
|--------------|--------------------------------------------------|
| Backend      | LangChain, Python, FastAPI, Chroma               |
| Frontend     | React, Vite, TypeScript, TailwindCSS             |
| Models       | Hugging Face BLOOMZ / Mistral 7B API             |
| Deployment   | Docker, Docker Compose                           |
| Dev Platform | Google Colab (for notebook version)              |

---

## ğŸ”— Try in Google Colab

<p align="center">
  <a href="https://colab.research.google.com/drive/1iPu5mldaozOhWdYf6jojFCZ3why0zgQ_?usp=sharing" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
  </a>
</p>

Open this notebook to run the full MEDA pipeline â€” no local setup needed.

---

## ğŸš€ Quick Start (Production)

```bash
docker-compose up -d --build
```

#### Frontend: http://localhost:3000
#### API: http://localhost:8000

### To stop:
```
docker-compose down
```

## ğŸ›  Development Setup

### Frontend

```bash
cd frontend
npm install
npm run dev
```
â†’ Available at http://localhost:3000

### Backend

```bash
cd backend
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
python app.py
```

ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: http://localhost:3000
â†’ API docs available at http://localhost:8000/docs

---

## ğŸ“š Data Sources

- [PubMed abstracts (open biomedical literature)](https://pubmed.ncbi.nlm.nih.gov/)
- Clinical recommendations (where available)
- Synthetic patient records (for testing)

---

## ğŸ” Related Work

Several systems inspired the design of MEDA:

- **BioGPT (Microsoft)** â€“ a transformer model pre-trained on biomedical texts. While accurate, it requires fine-tuning and lacks real-time retrieval.
- **PubMedQA** â€“ dataset and baseline models for question answering on PubMed; serves as benchmark for future MEDA evaluation.
- **LlamaIndex / Haystack** â€“ alternative frameworks for RAG pipelines, focused on modularity and custom retrievers.

Compared to these:
- MEDA is lightweight, easy to deploy (Colab or Docker), and uses RAG with plug-and-play LLMs.
- It emphasizes explainability by showing document context next to answers.
- Designed with student-friendly and clinical use cases in mind.

---

## ğŸ§  State of the Art (SOTA)

Recent advancements in domain-specific question answering (QA) systems, especially in the medical field, highlight the power and limitations of existing approaches:

### ğŸ”¬ Biomedical QA Benchmarks
- **BioASQ**: A gold-standard benchmark for biomedical QA. Most SOTA models rely on large-scale pretraining and require fine-tuning.
- **MedMCQA**: A multiple-choice QA benchmark using Indian medical entrance exam questions, testing deep reasoning ability in medicine.

### ğŸ’¡ Notable SOTA Models

| Model         | Approach                         | Key Strengths                         |
|---------------|----------------------------------|----------------------------------------|
| BioGPT        | Pretrained biomedical transformer| Strong generation, domain-specific     |
| GatorTron     | 8.9B parameter clinical model     | High performance in clinical NLP tasks |
| Med-PaLM 2    | Instruction-tuned for medicine   | Reaches expert-level medical QA        |
| PubMedBERT    | Pretrained on PubMed abstracts   | Great for retrieval + classification   |

### ğŸ”„ Comparison with MEDA

| Feature            | MEDA                    | SOTA Models (e.g. Med-PaLM 2, GatorTron) |
|--------------------|-------------------------|------------------------------------------|
| Open-source        | âœ… Yes                  | âŒ Often closed or limited access        |
| Real-time RAG      | âœ… Yes                  | âŒ Mostly static or fine-tuned outputs   |
| Medical tuning     | âŒ Not yet              | âœ… Strong tuning on medical corpora      |
| Colab support      | âœ… Easy to run          | âŒ Often unavailable or costly           |

MEDA is not aiming to outperform closed-source giants like Med-PaLM, but rather:
- Be accessible
- Transparent
- Modular
- Easy to reproduce and extend in a course or academic setting

---

## ğŸ“Š Evaluation and Observations

Initial testing was conducted manually using ~10 diverse medical questions.

**Metrics (qualitative):**
- Relevance: âœ… Context retrieved from topically accurate PubMed fragments.
- Fluency: âœ… Answers are grammatically correct and understandable.
- Groundedness: âš ï¸ Hallucinations minimized when using < 5 context chunks.
- Latency: ~4s average on Mistral API (per query).

**Examples:**

> **Q:** What are the latest methods for breast cancer screening?  
> **A:** "Recent methods include digital mammography and MRI. Studies also support personalized screening based on genetic risk."

> **Q:** How does immunotherapy work in lung cancer?  
> **A:** "Immunotherapy activates the immune system to attack tumor cells. It is often used with checkpoint inhibitors like PD-1."

ğŸ“Œ A more formal evaluation (e.g. BioASQ or MedMCQA benchmarks) is part of planned future work.

---

## ğŸ“‘ References

- Mehdi Iraqui, [Medical RAG using LangChain + Mistral 7B](https://medium.com/@mehdi.iraqui/medical-rag-system-using-langchain-and-mistral-7b-31c3982b0b52)
- [LangChain Documentation](https://docs.langchain.com)
- [Hugging Face](https://huggingface.co)

---

## âœ… Status

- âœ… Embedding and indexing medical data
- âœ… Retrieval of relevant context chunks
- âœ… Prompt creation and LLM generation
- âœ… Google Colab notebook for quick testing
- âœ… Web UI for interactive use

---

## ğŸš§ Future Work

- RAG + fine-tuned LLMs on clinical QA datasets
- Model evaluation on benchmarks (BioASQ, MedMCQA)
- Integration of PDF ingestion pipeline
- Multilingual support

---

## ğŸ“¬ Contact

Project author: **Dmitry Kardashevsky**  
âœ‰ï¸ Email: [kardashevskydv@gmail.com](mailto:kardashevskydv@gmail.com)  
ğŸŒ GitHub: [github.com/kardashevsky](https://github.com/kardashevsky)
ğŸ“„ LinkedIn: [linkedin.com/in/kardashevsky](https://www.linkedin.com/in/kardashevsky/)

For questions, suggestions, or contributions â€” feel free to reach out.
