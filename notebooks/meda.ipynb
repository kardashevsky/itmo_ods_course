{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdFXnOAP2DUb",
        "outputId": "c5476683-a0d3-4d6c-ae9a-3f7edb704255"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGU_fzDB2uRH",
        "outputId": "5d49fe13-2e8a-45ee-d3fc-05de577c7dfc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFgyqDIQl4S3",
        "outputId": "5149820d-7606-46da-c0d5-ccfac2fb6ebc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.13 (from langchain-community)\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.27 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.13 langchain-community-0.3.13 langchain-core-0.3.28 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем эмбеддинги и тексты"
      ],
      "metadata": {
        "id": "E4zhV0cz53Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Путь к сохранённым данным\n",
        "embeddings_path = \"embeddings.npy\"  # Путь к файлу с эмбеддингами\n",
        "texts_path = \"texts.txt\"  # Путь к файлу с текстами\n",
        "\n",
        "# Загрузка эмбеддингов\n",
        "embeddings = np.load(embeddings_path)\n",
        "print(f\"Эмбеддинги загружены: {embeddings.shape}\")\n",
        "\n",
        "# Загрузка текстов\n",
        "with open(texts_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    texts = [line.strip() for line in f]\n",
        "print(f\"Тексты загружены: {len(texts)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UW9kIql52pR",
        "outputId": "9310cbad-aa2a-420a-ebef-0cf4b3bca04d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эмбеддинги загружены: (53542, 384)\n",
            "Тексты загружены: 53542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Убедимся, что количество эмбеддингов совпадает с количеством текстов\n",
        "assert len(embeddings) == len(texts), \"Количество эмбеддингов и текстов должно совпадать!\"\n",
        "\n",
        "# Создание FAISS индекса\n",
        "embedding_dim = embeddings.shape[1]  # Размерность эмбеддингов\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # Индекс для поиска по L2-норме (евклидово расстояние)\n",
        "\n",
        "# Добавление эмбеддингов в индекс\n",
        "index.add(embeddings)\n",
        "print(f\"Добавлено {index.ntotal} эмбеддингов в индекс.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hxAefz066tY",
        "outputId": "0eddf23d-6849-4e10-ca9d-309964faaf94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлено 53542 эмбеддингов в индекс.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение индекса на диск\n",
        "faiss.write_index(index, \"faiss_index\")\n",
        "print(\"Индекс сохранён.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_34LSbzs7sWN",
        "outputId": "6cdfb163-47fa-401d-c4b7-83f57dd36231"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс сохранён.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Загрузка индекса с диска\n",
        "# index = faiss.read_index(\"faiss_index\")\n",
        "# print(\"Индекс загружен.\")\n"
      ],
      "metadata": {
        "id": "m7wP_Y8n7uLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Загрузка предобученной модели и токенизатора\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Компактная модель для векторизации текстов\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Перенос модели на устройство (GPU, если доступен)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Функция для получения эмбеддингов с использованием GPU\n",
        "def get_embedding(text):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "    tokens = {key: value.to(device) for key, value in tokens.items()}  # Перенос данных на устройство\n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)\n",
        "    return output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Среднее по токенам"
      ],
      "metadata": {
        "id": "Yi5SLXWVNNyJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_texts(query_embedding, index, texts, k=5):\n",
        "    \"\"\"\n",
        "    Выполняет поиск ближайших соседей в индексе FAISS.\n",
        "    query_embedding: np.array, эмбеддинг запроса (размерность должна совпадать с индексом)\n",
        "    index: faiss.Index, индекс FAISS\n",
        "    texts: list[str], список текстов\n",
        "    k: int, количество ближайших соседей\n",
        "    \"\"\"\n",
        "    distances, indices = index.search(query_embedding.reshape(1, -1), k)\n",
        "    results = [(texts[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# Пример использования\n",
        "query_embedding = embeddings[0]  # Пример: первый эмбеддинг как запрос\n",
        "retrieved_texts = retrieve_texts(query_embedding, index, texts, k=5)\n",
        "\n",
        "# Вывод результатов\n",
        "for text, distance in retrieved_texts:\n",
        "    print(f\"Текст: {text} (Расстояние: {distance})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUoZWgIV71QX",
        "outputId": "43cdf405-64e4-4309-a221-a52ebac93b93"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст: (--)-alpha-Bisabolol has a primary antipeptic action depending on dosage, which is not caused by an alteration of the pH-value. The proteolytic activity of pepsin is reduced by 50 percent through addition of bisabolol in the ratio of 1/0.5. The antipeptic action of bisabolol only occurs in case of direct contact. In case of a previous contact with (Расстояние: 0.0)\n",
            "Текст: by specific pepsin inactivators. The pH activity curve of the purified enzyme showed two optima near pH 3 and 4. The relative activities at these optimal pH values were affected by salt concentration. Experimental evidence indicated that the two-optima phenomenon is a property of a single enzyme species. (Расстояние: 0.7951406836509705)\n",
            "Текст: of cystine, aspartic acid, and serine. It inhibited trypsin in a molar ratio of 1 : 1 and alpha-chymotrypsin in a molar ratio of 2 : 1. It, however, inhibited neither pepsin nor pronase. It was relatively stable to heat treatment in the acidic medium, but not in the alkaline medium. Neither pepsin nor pronase destroyed the inhibitory function. (Расстояние: 0.79738450050354)\n",
            "Текст: corrected by adding pepsin. Such characteristics indicate that activation at low pH is catalysed by intrinsic enzymes. 3. Separation and/or dilution of the activating enzyme during ion-exchange chromatography concealed the eluted position of inactive renin and reduced the amount recovered. Only after full activation of the eluted renin was (Расстояние: 0.797764241695404)\n",
            "Текст: did not alter IF in any of the parameters mentioned above. Pepsin failed to alter either R protein or IF. THESE STUDIES SUGGEST THE FOLLOWING: (a) that Cbl is bound almost exclusively to R protein in the acid milieu of the stomach, rather than to IF as has been assumed previously; (b) that Cbl remains bound to R protein in the slightly alkaline (Расстояние: 0.823165237903595)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "query = \"What are the common treatments for cancer?\"\n",
        "query_embedding = get_embedding(query)  # Получаем эмбеддинг запроса\n",
        "results = retrieve_texts(query_embedding, index, texts, k=5)\n",
        "\n",
        "# Вывод результатов\n",
        "for text, distance in results:\n",
        "    print(f\"Текст: {text} (Расстояние: {distance})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UyzCaMWNbdN",
        "outputId": "fe496fc5-0950-4c71-950f-a9b19d156538"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст: appears to have a future as an adjunct to existing therapy in order to control as much as to cure residual tumour. (Расстояние: 41.236751556396484)\n",
            "Текст: of the treatment are looked at. (Расстояние: 41.60153579711914)\n",
            "Текст: demonstrates the urgent need to complete randomized controlled trials of treatment in this group. (Расстояние: 41.81917953491211)\n",
            "Текст: medical or surgical therapeutic measures applied may be fully effective. (Расстояние: 41.88026428222656)\n",
            "Текст: and made recommendations for surgical management. (Расстояние: 41.95117950439453)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Настройка API\n",
        "api_key = \"4Cs8hBRAzeJjgfAYR6ilpTFOtsTvCqrr\"\n",
        "model_LLM = \"mistral-large-latest\"\n",
        "base_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "def generate_answer_with_mistral(prompt):\n",
        "    payload = {\n",
        "        \"model\": model_LLM,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 500,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    response = requests.post(base_url, json=payload, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Пример генерации ответа\n",
        "prompt = \"What are the latest advancements in cancer treatments?\"\n",
        "response = generate_answer_with_mistral(prompt)\n",
        "print(f\"Ответ: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757uXOui--Rm",
        "outputId": "c074ce9d-9baa-41f6-b432-cac018c08218"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ответ: Cancer treatment is a rapidly evolving field, with numerous advancements being made in recent years. Here are some of the latest developments:\n",
            "\n",
            "1. **Immunotherapy**: This approach uses the body's own immune system to fight cancer. Recent advancements include:\n",
            "   - **CAR T-cell therapy**: This involves engineering the patient's own T cells to recognize and attack cancer cells. It has shown promising results in certain types of leukemia and lymphoma.\n",
            "   - **Checkpoint inhibitors**: Drugs like PD-1/PD-L1 and CTLA-4 inhibitors help the immune system recognize and attack cancer cells. These have been approved for various types of cancer, including melanoma, lung cancer, and renal cell carcinoma.\n",
            "   - **Cancer vaccines**: These are designed to treat existing cancers by stimulating the body's immune response. Some recent vaccines are showing promise in clinical trials.\n",
            "\n",
            "2. **Targeted Therapies**: These drugs target specific molecules involved in cancer growth and progression. Recent advancements include:\n",
            "   - **PARP inhibitors**: These drugs target an enzyme involved in DNA repair and have shown efficacy in treating ovarian, breast, and prostate cancers with specific genetic mutations.\n",
            "   - **TRK inhibitors**: These target a specific type of fusion protein found in some cancers, offering a novel approach to treating various types of tumors.\n",
            "\n",
            "3. **Personalized Medicine**: This involves tailoring treatments to the specific characteristics of a patient's tumor. Advancements include:\n",
            "   - **Next-generation sequencing (NGS)**: This technology allows for the rapid and comprehensive identification of genetic alterations in tumors, helping to guide treatment decisions.\n",
            "   - **Liquid biopsies**: These are minimally invasive tests that can detect cancer cells or DNA circulating in the blood, helping to monitor disease progression and treatment response.\n",
            "\n",
            "4. **Oncolytic Virus Therapy**: This involves using modified viruses to infect and kill cancer cells. Talimogene laherparepvec (T-VEC) is an example of an oncolytic virus therapy approved for the treatment of certain types of skin and lymph node cancers.\n",
            "\n",
            "5. **Artificial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_with_mistral(prompt):\n",
        "    if not isinstance(prompt, str):\n",
        "        raise ValueError(f\"Prompt должен быть строкой, получен {type(prompt)}\")\n",
        "\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 500,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    response = requests.post(base_url, json=payload, headers=headers)\n",
        "    response.raise_for_status()  # Вызывает исключение при HTTP-ошибках\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
      ],
      "metadata": {
        "id": "bC3yw_ASUepy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_pipeline(query, index, texts, mistral_api_key, k=5):\n",
        "    \"\"\"\n",
        "    Полная цепочка RAG: поиск + генерация.\n",
        "    query: текстовый запрос\n",
        "    query_embedding: np.array, эмбеддинг запроса.\n",
        "    index: faiss.Index, индекс FAISS.\n",
        "    texts: list[str], список текстов.\n",
        "    mistral_api_key: str, ключ API для Mistral.\n",
        "    k: int, количество ближайших соседей.\n",
        "    \"\"\"\n",
        "    # 1. Поиск релевантных текстов\n",
        "    query_embedding = get_embedding(query)\n",
        "    retrieved_texts = retrieve_texts(query_embedding, index, texts, k)\n",
        "    context = \"\\n\\n\".join([text for text, _ in retrieved_texts])\n",
        "\n",
        "    # 2. Формирование запроса к модели\n",
        "    prompt = f\"Based on the following context, answer the query:\\n\\n{context}\\n\\nQuery:\\n\\n {query}\"\n",
        "\n",
        "    # 3. Генерация ответа\n",
        "    answer = generate_answer_with_mistral(prompt)\n",
        "\n",
        "    return {\"answer\": answer, \"context\": context}\n"
      ],
      "metadata": {
        "id": "gHq1Ik1y_szd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "query = \"What are the latest advancements in cancer treatments?\"\n",
        "result = rag_pipeline(query, index, texts, api_key, k=5)\n",
        "\n",
        "# Вывод результата\n",
        "print(f\"Ответ: {result['answer']}\")\n",
        "print(\"\\nКонтекст:\")\n",
        "print(result[\"context\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjM1FPJ_6rL",
        "outputId": "d0ebbfd6-ae4b-4323-d0e3-5b339622ab94"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ответ: The provided context does not specifically mention the latest advancements in cancer treatments, but it does discuss some aspects of cancer management. Here are a few key points from the text:\n",
            "\n",
            "1. **Combination Therapy**: The text mentions that a certain approach \"appears to have a future as an adjunct to existing therapy\" to control or cure residual tumors. This suggests that combination therapies, using multiple treatment methods, are being considered or implemented.\n",
            "\n",
            "2. **Surgical Management**: The text highlights recommendations for surgical management, indicating that surgical techniques continue to be an important part of cancer treatment.\n",
            "\n",
            "3. **Randomized Controlled Trials**: The text emphasizes the need for randomized controlled trials, which are essential for evaluating the effectiveness and safety of new treatments.\n",
            "\n",
            "For a more comprehensive and up-to-date list of the latest advancements in cancer treatments, you might want to look into recent developments in fields such as:\n",
            "\n",
            "- **Immunotherapy**: Treatments that use the body's own immune system to fight cancer.\n",
            "- **Targeted Therapy**: Drugs that target specific molecular changes in cancer cells.\n",
            "- **Personalized Medicine**: Treatments tailored to the individual characteristics of a patient's cancer.\n",
            "- **Genomic Medicine**: The use of genetic information to guide treatment decisions.\n",
            "- **CAR T-cell Therapy**: A type of treatment in which a patient's T cells are changed in the laboratory so they will attack cancer cells.\n",
            "- **Advances in Radiation Therapy**: Techniques such as proton beam therapy and stereotactic body radiation therapy (SBRT).\n",
            "- **Nanotechnology**: The use of nanoparticles for targeted drug delivery and imaging.\n",
            "- **Gene Editing**: Technologies like CRISPR-Cas9 for modifying the genetic makeup of cancer cells.\n",
            "\n",
            "These areas represent some of the most cutting-edge research and clinical applications in cancer treatment.\n",
            "\n",
            "Контекст:\n",
            "appears to have a future as an adjunct to existing therapy in order to control as much as to cure residual tumour.\n",
            "\n",
            "and made recommendations for surgical management.\n",
            "\n",
            "medical or surgical therapeutic measures applied may be fully effective.\n",
            "\n",
            "of the treatment are looked at.\n",
            "\n",
            "demonstrates the urgent need to complete randomized controlled trials of treatment in this group.\n"
          ]
        }
      ]
    }
  ]
}
